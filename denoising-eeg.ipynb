{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7500594,"sourceType":"datasetVersion","datasetId":4367700},{"sourceId":8106877,"sourceType":"datasetVersion","datasetId":4788287}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### models architectures\n##These are our first architectures from EEGdenoisenet paper and code: \n##https://github.com/ncclabsustech/EEGdenoiseNet\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models, Input, Sequential\n\n# Author: Haoming Zhang\n\ndef fcNN(datanum):\n  model = tf.keras.Sequential()\n  model.add(Input(shape=(datanum,)))\n  model.add(layers.Dense(datanum, activation=tf.nn.relu ))\n  model.add(layers.Dropout(0.3))\n\n\n  model.add(layers.Dense(datanum))\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Dense(datanum))\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Dense(datanum))\n  model.summary()\n  return model\n\n\ndef RNN_lstm(datanum):\n  model = tf.keras.Sequential()\n  model.add(Input(shape=(datanum,1)))\n  model.add(layers.LSTM(1,return_sequences = True ))\n\n  model.add(layers.Flatten())\n\n  model.add(layers.Dense(datanum))\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Dense(datanum))\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Dense(datanum))\n  model.summary()\n  return model\n\n\ndef simple_CNN(datanum):\n  model = tf.keras.Sequential()\n\n  model.add(layers.Conv1D(64, 3, strides=1, padding='same',input_shape=[ datanum, 1]))\n  model.add(layers.BatchNormalization())\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Conv1D(64, 3, strides=1, padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Conv1D(64, 3, strides=1, padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  #num4\n  model.add(layers.Conv1D(64, 3, strides=1, padding='same'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.ReLU())\n  model.add(layers.Dropout(0.3))\n\n  model.add(layers.Flatten())\n  model.add(layers.Dense(datanum))\n\n  model.summary()\n\n  return model\n\n\n# Resnet Basic Block module。\nclass Res_BasicBlock(layers.Layer):\n  def __init__(self,kernelsize, stride=1):\n    super(Res_BasicBlock, self).__init__()\n    self.bblock = Sequential([layers.Conv1D(32,kernelsize,strides=stride,padding=\"same\"),\n                              layers.BatchNormalization(),\n                              layers.ReLU(),\n                              layers.Conv1D(16,kernelsize,strides=1,padding=\"same\"),\n                              layers.BatchNormalization(),\n                              layers.ReLU(),\n                              layers.Conv1D(32,kernelsize,strides=1,padding=\"same\"),\n                              layers.BatchNormalization(),\n                              layers.ReLU()])\n                              \n    self.jump_layer = lambda x:x\n\n\n  def call(self, inputs, training=None):\n\n    #Through the convolutional layer\n    out = self.bblock(inputs)\n\n    #skip\n    identity = self.jump_layer(inputs)\n\n    output = layers.add([out, identity])  #layers下面有一个add，把这2个层添加进来相加。\n    \n    return output\n\n\nclass BasicBlockall(layers.Layer):\n  def __init__(self, stride=1):\n    super(BasicBlockall, self).__init__()\n\n    self.bblock3 = Sequential([Res_BasicBlock(3),\n                              Res_BasicBlock(3)\n                              ])                      \n    \n    self.bblock5 = Sequential([Res_BasicBlock(5),\n                              Res_BasicBlock(5)\n                              ])                      \n\n    self.bblock7 = Sequential([Res_BasicBlock(7),\n                              Res_BasicBlock(7)\n                              ])\n                              \n    self.downsample = lambda x:x\n\n\n  def call(self, inputs, training=None):\n \n    out3 = self.bblock3(inputs)\n    out5 = self.bblock5(inputs)\n    out7 = self.bblock7(inputs)\n\n    out = tf.concat( values = [out3,out5,out7] , axis = -1)\n\n    return out\n\n\ndef Complex_CNN(datanum):\n  model = Sequential()\n  model.add(layers.Conv1D(32 ,5,strides=1,padding=\"same\",input_shape=( datanum, 1)))\n  model.add(layers.BatchNormalization())\n  model.add( layers.ReLU())\n\n  model.add(BasicBlockall())\n\n  model.add(layers.Conv1D(32 ,1,strides=1,padding=\"same\"))\n  model.add(layers.BatchNormalization())\n  model.add( layers.ReLU())\n\n  model.add(layers.Flatten())\n  model.add(layers.Dense(datanum))\n\n  model.summary()\n  \n  return model","metadata":{"execution":{"iopub.status.busy":"2024-05-05T23:58:38.595566Z","iopub.execute_input":"2024-05-05T23:58:38.595982Z","iopub.status.idle":"2024-05-05T23:58:38.624375Z","shell.execute_reply.started":"2024-05-05T23:58:38.595948Z","shell.execute_reply":"2024-05-05T23:58:38.623464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####this is the last architecture, called LU-net architecture\n##we can find the paper here: https://ieeexplore.ieee.org/abstract/document/10173517\n\n#LU-Net architecture\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv1D, ReLU, Bidirectional, LSTM, UpSampling1D, Concatenate, Input, Conv2DTranspose\n\ndef encoder_decoder(datanum):\n    # Encoder\n    input_layer = Input(shape=(datanum,1))\n    x = input_layer\n    encoder_outputs = []\n    lstm_outputs =[]\n    filters_encoder = [16, 32, 32, 64, 64]\n    filters_lstm = [8, 16,16,32,32] \n    strides_encoder = [1,2,2,2,2]\n    for i in range(1, 6):\n        if i > 1:\n            x = encoder_outputs[-1]  # Pass output from previous encoder as input\n        x = Conv1D(filters=filters_encoder[i-1], kernel_size=31, strides=strides_encoder[i-1], padding='same')(x)\n        x = ReLU()(x)\n        encoder_outputs.append(x)\n        x = Bidirectional(LSTM(units=filters_lstm[i-1],return_sequences=True))(encoder_outputs[-1])\n        lstm_outputs.append(x)\n\n    \n    # Bottleneck\n    bottleneck_output = Conv1D(filters=128, kernel_size=31, strides=2, padding='same')(encoder_outputs[-1])\n    \n    # Decoder\n    decoder_outputs = []\n    filters_decoder = [32,32,32,64, 64]               \n    for i in range(5, 0, -1):\n        if i < 5:\n            x = Concatenate()([decoder_outputs[-1], lstm_outputs[i]])  # Concatenate with LSTM output\n        else:\n            x = bottleneck_output\n        x = Conv1D(filters=filters_decoder[i-1], kernel_size=31,strides= 1, padding='same')(x)\n        x = ReLU()(x)\n        x = UpSampling1D()(x)\n        decoder_outputs.append(x)\n    \n    # Final convolution layer\n    x = Concatenate()([decoder_outputs[-1], lstm_outputs[0]])\n    output = Conv1D(filters=1, kernel_size=31 ,strides= 1, padding='same')(x)\n    output = tf.keras.layers.Reshape((datanum,))(output)\n    \n    # Define model\n    model = tf.keras.Model(inputs=input_layer, outputs=output)\n    model.summary()\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LU-Net architecture 3 layers\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv1D, ReLU, Bidirectional, LSTM, UpSampling1D, Concatenate, Input, Conv2DTranspose\n\ndef encoder_decoder(datanum):\n    # Encoder\n    input_layer = Input(shape=(datanum,1))\n    x = input_layer\n    encoder_outputs = []\n    lstm_outputs =[]\n    filters_encoder = [16, 32, 32]\n    filters_lstm = [8, 16,16] \n    strides_encoder = [1,2,2]\n    for i in range(1, 4):\n        if i > 1:\n            x = encoder_outputs[-1]  # Pass output from previous encoder as input\n        x = Conv1D(filters=filters_encoder[i-1], kernel_size=31, strides=strides_encoder[i-1], padding='same')(x)\n        x = ReLU()(x)\n        encoder_outputs.append(x)\n        x = Bidirectional(LSTM(units=filters_lstm[i-1],return_sequences=True))(encoder_outputs[-1])\n        lstm_outputs.append(x)\n\n    \n    # Bottleneck\n    bottleneck_output = Conv1D(filters=128, kernel_size=31, strides=2, padding='same')(encoder_outputs[-1])\n    \n    # Decoder\n    decoder_outputs = []\n    filters_decoder = [32,32,32]               \n    for i in range(3, 0, -1):\n        if i < 3:\n            x = Concatenate()([decoder_outputs[-1], lstm_outputs[i]])  # Concatenate with LSTM output\n        else:\n            x = bottleneck_output\n        x = Conv1D(filters=filters_decoder[i-1], kernel_size=31,strides= 1, padding='same')(x)\n        x = ReLU()(x)\n        x = UpSampling1D()(x)\n        decoder_outputs.append(x)\n    \n    # Final convolution layer\n    x = Concatenate()([decoder_outputs[-1], lstm_outputs[0]])\n    output = Conv1D(filters=1, kernel_size=31 ,strides= 1, padding='same')(x)\n    output = tf.keras.layers.Reshape((datanum,))(output)\n    \n    # Define model\n    model = tf.keras.Model(inputs=input_layer, outputs=output)\n    model.summary()\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########a code for preparing the data\n\nimport sklearn.model_selection as ms\nimport numpy as np\nimport scipy.io as sio\nimport math\n# Author: Haoming Zhang\n#The code here not only include data importing, but also data standardization and the generation of analog noise signals\n\ndef get_rms(records):\n   \n    return math.sqrt(sum([x ** 2 for x in records]) / len(records))\n\n\ndef random_signal(signal,combin_num):\n    # Random disturb and augment signal\n    random_result=[]\n\n    for i in range(combin_num):\n        random_num = np.random.permutation(signal.shape[0])\n        shuffled_dataset = signal[random_num, :]\n        shuffled_dataset = shuffled_dataset.reshape(signal.shape[0],signal.shape[1])\n        random_result.append(shuffled_dataset)\n    \n    random_result  = np.array(random_result)\n\n    return  random_result\n\n\n\ndef prepare_data(EEG_all, EMG_all , EOG_all, combin_num, train_per, noise_type):\n    # Here we use eeg and noise signal to generate scale transed training, validation, test signal\n    EEG_all_random = np.squeeze(random_signal(signal = EEG_all, combin_num = 1))\n    noise_all_random = np.squeeze(random_signal(signal = EMG_all, combin_num = 1))\n    EOG_all_random = np.squeeze(random_signal(signal = EOG_all, combin_num = 1))\n\n    if noise_type == 'EMG':  # Training set will Reuse some of the EEG signal to much the number of EMG\n        reuse_num = noise_all_random.shape[0] - EEG_all_random.shape[0]\n        EEG_reuse = EEG_all_random[0 : reuse_num, :]\n        EEG_all_random = np.vstack([EEG_reuse, EEG_all_random])\n        print('EEG segments after reuse: ',EEG_all_random.shape[0])\n\n    elif noise_type == 'EOG':  # We will drop some of the EEG signal to much the number of EMG\n        EEG_all_random = EEG_all_random[0:noise_all_random.shape[0]]\n        print('EEG segments after drop: ',EEG_all_random.shape[0])\n    \n    # get the \n    timepoint = noise_all_random.shape[1]\n    train_num = round(train_per * EEG_all_random.shape[0]) # the number of segmentations used in training process\n    validation_num = round((EEG_all_random.shape[0] - train_num) / 2) # the number of segmentations used in validation process\n    #test_num = EEG_all_random.shape[0] - train_num - validation_num  # Rest are the number of segmentations used in test process\n\n    train_eeg = EEG_all_random[0 : train_num, :]\n    validation_eeg = EEG_all_random[train_num : train_num + validation_num, :]\n    test_eeg = EEG_all_random[train_num + validation_num : EEG_all_random.shape[0], :]\n\n    train_noise = noise_all_random[0 : train_num, :]\n    validation_noise = noise_all_random[train_num : train_num + validation_num,:]\n    test_noise = noise_all_random[train_num + validation_num : noise_all_random.shape[0], :]\n    \n    \n    EEG_train = random_signal(signal = train_eeg, combin_num = combin_num).reshape(combin_num * train_eeg.shape[0], timepoint)\n    #####using amp wraping\n#     NOISE_train = magnitude_warping(train_noise)\n    #########\n    NOISE_train = random_signal(signal = train_noise, combin_num = combin_num).reshape(combin_num * train_noise.shape[0], timepoint)\n    ###########################################\n    #print(EEG_train.shape)\n    #print(NOISE_train.shape)\n    \n    #################################  simulate noise signal of training set  ##############################\n\n    #create random number between -10dB ~ 2dB\n    SNR_train_dB = np.random.uniform(-7, 4, (EEG_train.shape[0])) ##### 4 for EMG\n    print(SNR_train_dB.shape)\n    SNR_train = 10 ** (0.1 * (SNR_train_dB))\n\n    # combin eeg and noise for training set \n    noiseEEG_train=[]\n    NOISE_train_adjust=[]\n    print('EEG train: ',EEG_train.shape)\n    for i in range (EEG_train.shape[0]):\n        eeg=EEG_train[i].reshape(EEG_train.shape[1])\n        noise=NOISE_train[i].reshape(NOISE_train.shape[1])\n\n        coe=get_rms(eeg)/(get_rms(noise)*SNR_train[i])\n        noise = noise*coe\n        neeg = noise+eeg\n\n        NOISE_train_adjust.append(noise)\n        noiseEEG_train.append(neeg)\n\n    \n    noiseEEG_train=np.array(noiseEEG_train)\n    NOISE_train_adjust=np.array(NOISE_train_adjust)\n    print('noiseEEG_train',noiseEEG_train.shape)\n    \n\n    # variance for noisy EEG\n#     EEG_train_end_standard = []\n#     noiseEEG_train_end_standard = []\n\n#     for i in range(noiseEEG_train.shape[0]):\n#         # Each epochs divided by the standard deviation\n#         eeg_train_all_std = EEG_train[i] / np.std(noiseEEG_train[i])\n#         EEG_train_end_standard.append(eeg_train_all_std)\n\n#         noiseeeg_train_end_standard = noiseEEG_train[i] / np.std(noiseEEG_train[i])\n#         noiseEEG_train_end_standard.append(noiseeeg_train_end_standard)\n\n#     noiseEEG_train_end_standard = np.array(noiseEEG_train_end_standard)\n#     EEG_train_end_standard = np.array(EEG_train_end_standard)\n#     print('training data prepared', noiseEEG_train_end_standard.shape, EEG_train_end_standard.shape )\n\n    #################################  simulate noise signal of validation  ##############################\n\n#     SNR_val_dB = np.linspace(-7.0, 4.0, num=(10))\n#     np.random.shuffle(SNR_val_dB)\n#     SNR_val = 10 ** (0.1 * (SNR_val_dB))\n\n    eeg_val = np.array(validation_eeg)\n    noise_val = np.array(validation_noise)\n    \n    noise_val = random_signal(signal = noise_val, combin_num = combin_num).reshape(combin_num * noise_val.shape[0], timepoint)\n    eeg_val = random_signal(signal = eeg_val, combin_num = combin_num).reshape(combin_num * eeg_val.shape[0], timepoint)\n    \n    SNR_val_dB = np.random.uniform(-7, 4, (eeg_val.shape[0]))\n    SNR_val = 10 ** (0.1 * (SNR_val_dB))\n    # combin eeg and noise for test set \n    EEG_val = []\n    noise_EEG_val = []  \n        \n    noise_eeg_val = []\n    for j in range(eeg_val.shape[0]):\n        eeg = eeg_val[j]\n        noise = noise_val[j]\n            \n        coe = get_rms(eeg) / (get_rms(noise) * SNR_val[j])\n        noise = noise * coe\n        neeg = noise + eeg\n            \n        noise_eeg_val.append(neeg)\n        \n    #################################  simulate noise signal of test  ##############################\n\n    SNR_test_dB = np.linspace(-7.0, 2.0, num=(10))\n    SNR_test = 10 ** (0.1 * (SNR_test_dB))\n\n    eeg_test = np.array(test_eeg)\n    noise_test = np.array(test_noise)\n    \n    # combin eeg and noise for test set \n    EEG_test = []\n    noise_EEG_test = []\n    for i in range(10): \n        \n        noise_eeg_test = []\n        for j in range(eeg_test.shape[0]):\n            eeg = eeg_test[j]\n            noise = noise_test[j]\n            \n            coe = get_rms(eeg) / (get_rms(noise) * SNR_test[i])\n            noise = noise* coe\n            neeg = noise + eeg\n            \n            noise_eeg_test.append(neeg)\n        \n    ##########EOG splitting\n    \n    EOG_all_random = np.squeeze(random_signal(signal = EOG_all, combin_num = 1))\n    reuse_num_eog = noise_all_random.shape[0] - EOG_all_random.shape[0]\n    EOG_reuse = EOG_all_random[0 : reuse_num_eog, :] \n    EOG = np.vstack([EOG_reuse, EOG_all_random])\n    print(EOG.shape) ####5598 1024\n\n    \n    print('EOG segments: ',EOG.shape[0])\n    train_eog = EOG[0 : train_num, :]\n    validation_eog = EOG[train_num : train_num + validation_num,:]\n    test_eog = EOG[train_num + validation_num : noise_all_random.shape[0], :]\n    \n    ################increasing EOG rows by shifting augmentation\n#     EOG_train = geometric_augmentation(train_eog)\n    #####################randomly increasing EOG rows##############\n    EOG_train = random_signal(signal = train_eog, combin_num = combin_num).reshape(combin_num * train_eog.shape[0], timepoint)\n    ##########################\n    print('EOG train: ',EOG_train.shape[0])\n    \n    \n    #########for train EOG\n    #create random number between -10dB ~ 2dB\n    SNR_train_dB = np.random.uniform(-7, 2, (EEG_train.shape[0])) \n    print(SNR_train_dB.shape)\n    SNR_train = 10 ** (0.1 * (SNR_train_dB))\n\n    # combin eeg and noise for training set \n    noiseEEG_train_final=[]\n    EOG_train_adjust=[]\n    for i in range (EEG_train.shape[0]):\n        eeg=EEG_train[i].reshape(EEG_train.shape[1])\n        eog=EOG_train[i].reshape(EOG_train.shape[1])\n\n        coe_eog=get_rms(eeg)/(get_rms(eog)*SNR_train[i])\n        eog = eog*coe_eog\n        cont = eog+noiseEEG_train[i]\n\n        EOG_train_adjust.append(eog)\n        noiseEEG_train_final.append(cont)\n\n    noiseEEG_train_final=np.array(noiseEEG_train_final)\n    EOG_train_adjust=np.array(EOG_train_adjust)\n    print('EEG train: ',EEG_train.shape)\n    print('contam final',noiseEEG_train_final.shape)\n           \n    #############for val EOG\n#     SNR_val_dB = np.linspace(-7.0, 2.0, num=(10))\n#     SNR_val = 10 ** (0.1 * (SNR_val_dB))\n\n    eog_val = random_signal(signal = validation_eog, combin_num = combin_num).reshape(combin_num * validation_eog.shape[0], timepoint)\n    SNR_val_dB = np.random.uniform(-7, 2, (eog_val.shape[0]))\n    SNR_val = 10 ** (0.1 * (SNR_val_dB))\n    \n    # combin eeg and noise for test set \n    EEG_val = []\n    noise_EEG_val_final = []\n\n    noise_eeg_val_final = []\n    for j in range(eeg_val.shape[0]):\n        eeg = eeg_val[j]\n        eog = eog_val[j]\n            \n        coe_eog = get_rms(eeg) / (get_rms(eog) * SNR_val[j])\n        eog = eog * coe_eog\n        cont = eog + noise_eeg_val[j]   ####EMG EOG\n            \n        noise_eeg_val_final.append(cont)\n        \n    EEG_val.extend(eeg_val)\n    noise_EEG_val_final.extend(noise_eeg_val_final)\n\n\n    EEG_val = np.array(EEG_val)\n    noise_EEG_val_final = np.array(noise_EEG_val_final)\n           \n    ################test EOG\n    SNR_test_dB = np.linspace(-7.0, 2.0, num=(10))\n    SNR_test = 10 ** (0.1 * (SNR_test_dB))\n\n    eog_test = np.array(test_eog)\n    \n    # combin eeg and noise for test set \n    EEG_test = []\n    noise_EEG_test_final = []\n    for i in range(10): \n        \n        noise_eeg_test_final = []\n        for j in range(eeg_test.shape[0]):\n            eeg = eeg_test[j]\n            eog = eog_test[j]\n            \n            coe_eog = get_rms(eeg) / (get_rms(eog) * SNR_test[i])\n            eog = eog* coe_eog\n            cont = eog + noise_eeg_test[j]   #####EOG EMG\n            \n            noise_eeg_test_final.append(cont)\n        \n        EEG_test.extend(eeg_test)\n        noise_EEG_test_final.extend(noise_eeg_test_final)\n\n    EEG_test = np.array(EEG_test)\n    noise_EEG_test_final = np.array(noise_EEG_test_final)\n    \n\n           \n    ##############standardization train data\n           \n    EEG_train_end_standard = []\n    noiseEEG_train_end_standard = []\n\n    for i in range(noiseEEG_train_final.shape[0]):\n        # Each epochs divided by the standard deviation\n        eeg_train_all_std = EEG_train[i] / np.std(noiseEEG_train_final[i])\n        EEG_train_end_standard.append(eeg_train_all_std)\n\n        noiseeeg_train_end_standard = noiseEEG_train_final[i] / np.std(noiseEEG_train_final[i])\n        noiseEEG_train_end_standard.append(noiseeeg_train_end_standard)\n\n    noiseEEG_train_end_standard = np.array(noiseEEG_train_end_standard)\n    EEG_train_end_standard = np.array(EEG_train_end_standard)\n    print('training data prepared', noiseEEG_train_end_standard.shape, EEG_train_end_standard.shape )\n\n           \n    ##############standardization validation data\n    EEG_val_end_standard = []\n    noiseEEG_val_end_standard = []\n\n    for i in range(noise_EEG_val_final.shape[0]):\n        \n        # store std value to restore EEG signal\n        std_value = np.std(noise_EEG_val_final[i])\n        #std_VALUE.append(std_value)\n\n        # Each epochs of eeg and neeg was divide by the standard deviation\n        eeg_val_all_std = EEG_val[i] / std_value\n        EEG_val_end_standard.append(eeg_val_all_std)\n\n        noiseeeg_val_end_standard = noise_EEG_val_final[i] / std_value\n        noiseEEG_val_end_standard.append(noiseeeg_val_end_standard)\n\n    #std_VALUE = np.array(std_VALUE)\n    noiseEEG_val_end_standard = np.array(noiseEEG_val_end_standard)\n    EEG_val_end_standard = np.array(EEG_val_end_standard)\n    print('validation data prepared, validation data shape: ', noiseEEG_val_end_standard.shape, EEG_val_end_standard.shape)\n    \n           \n           \n    ##############standardization test data\n    EEG_test_end_standard = []\n    noiseEEG_test_end_standard = []\n    std_VALUE = []\n    for i in range(noise_EEG_test_final.shape[0]):\n        \n        # store std value to restore EEG signal\n        std_value = np.std(noise_EEG_test_final[i])\n        std_VALUE.append(std_value)\n\n        # Each epochs of eeg and neeg was divide by the standard deviation\n        eeg_test_all_std = EEG_test[i] / std_value\n        EEG_test_end_standard.append(eeg_test_all_std)\n\n        noiseeeg_test_end_standard = noise_EEG_test_final[i] / std_value\n        noiseEEG_test_end_standard.append(noiseeeg_test_end_standard)\n\n    std_VALUE = np.array(std_VALUE)\n    noiseEEG_test_end_standard = np.array(noiseEEG_test_end_standard)\n    EEG_test_end_standard = np.array(EEG_test_end_standard)\n    print('test data prepared, test data shape: ', noiseEEG_test_end_standard.shape, EEG_test_end_standard.shape)       \n           \n           \n    return noiseEEG_train_end_standard, EEG_train_end_standard, noiseEEG_val_end_standard, EEG_val_end_standard, noiseEEG_test_end_standard, EEG_test_end_standard, std_VALUE\n  ","metadata":{"execution":{"iopub.status.busy":"2024-05-05T23:19:45.373652Z","iopub.execute_input":"2024-05-05T23:19:45.374035Z","iopub.status.idle":"2024-05-05T23:19:45.871472Z","shell.execute_reply.started":"2024-05-05T23:19:45.374002Z","shell.execute_reply":"2024-05-05T23:19:45.870714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##functions for calculating the loss\n##rrmse is the most used by us\n\nimport tensorflow as tf\n\n################################# loss functions ##########################################################\n\ndef denoise_loss_mse(denoise, clean):      \n  loss = tf.losses.mean_squared_error(denoise, clean)\n  return tf.reduce_mean(loss)\n\ndef denoise_loss_rmse(denoise, clean):      #tmse\n  loss = tf.losses.mean_squared_error(denoise, clean)\n  #loss2 = tf.losses.mean_squared_error(noise, clean)\n  return tf.math.sqrt(tf.reduce_mean(loss))\n\ndef denoise_loss_rrmset(denoise, clean):      #tmse\n  rmse1 = denoise_loss_rmse(denoise, clean)\n  rmse2 = denoise_loss_rmse(clean, tf.zeros(clean.shape[0], tf.float64))\n  #loss2 = tf.losses.mean_squared_error(noise, clean)\n  return rmse1/rmse2","metadata":{"execution":{"iopub.status.busy":"2024-05-05T23:19:51.829662Z","iopub.execute_input":"2024-05-05T23:19:51.830047Z","iopub.status.idle":"2024-05-05T23:19:51.836901Z","shell.execute_reply.started":"2024-05-05T23:19:51.830010Z","shell.execute_reply":"2024-05-05T23:19:51.835926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **for normal run:**","metadata":{}},{"cell_type":"code","source":"###train code\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom functools import partial\nfrom tqdm import tqdm\nfrom IPython.display import clear_output \nimport os  \nimport math\nimport datetime\n\n# Author: Haoming Zhang\n# Here is the part of denoiseNet training process\n    \n@tf.function\ndef train_step(model, noiseEEG_batch, EEG_batch, optimizer , denoise_network, batch_size, datanum):\n\n    #本次训练参数初始化  parameter initialization in one step\n\n    mse_grads = 0\n    m_loss = 0\n      \n \n    with tf.GradientTape() as loss_tape:\n    \n        M_loss =  0\n        for x in range(noiseEEG_batch.shape[0]):\n    \n            noiseeeg_batch,eeg_batch =  noiseEEG_batch[x] , EEG_batch[x]\n\n            if denoise_network == 'fcNN':\n                noiseeeg_batch = tf.reshape(noiseeeg_batch, [1,datanum])\n            else:\n                noiseeeg_batch = tf.reshape(noiseeeg_batch, [1,datanum,1])\n\n            eeg_batch=tf.reshape(eeg_batch, [1,datanum,1])\n            denoiseoutput = model(noiseeeg_batch)\n            denoiseoutput = tf.reshape(denoiseoutput, [1,datanum,1])                          \n\n            m_loss = denoise_loss_mse(denoiseoutput,eeg_batch)   \n            M_loss += m_loss\n\n    \n        M_loss = M_loss / float(noiseEEG_batch.shape[0]) \n        \n        # calculate gradient\n        mse_grads = loss_tape.gradient(M_loss, model.trainable_variables)\n        #bp\n        optimizer.apply_gradients(zip(mse_grads, model.trainable_variables))\n\n    return  M_loss,  mse_grads[0]  #每一条EEG的loss从此输出\n\ndef test_step(model, noiseEEG_test, EEG_test):\n\n  denoiseoutput_test = model(noiseEEG_test)\n  loss = denoise_loss_mse(EEG_test, denoiseoutput_test)\n  #loss_rrmset = denoise_loss_rrmset(denoiseoutput_test, EEG_test)\n\n  return denoiseoutput_test, loss#, loss_rrmset\n\n\ndef train(model, noiseEEG,EEG, noiseEEG_val, EEG_val, epochs, batch_size,optimizer, denoise_network, result_location, foldername, train_num,prev_history,history):\n    if prev_history ==False:\n        # setup history variables and save history in a npy film\n        history = {}\n        history['grads'], history['loss']= {}, {}\n        train_mse_history, val_mse_history = [],[]\n        mse_grads_history = []\n        val_mse_min = 100.0      # any number bigger than 1\n    else:\n        history=history\n        train_mse_history, val_mse_history = history['loss']['train_mse'], history['loss']['val_mse']\n        mse_grads_history = history['grads']['mse'] \n        hlv=history['loss']['val_mse']\n        val_mse_min = float(hlv[-1]) # any number bigger than 1\n    \n        \n    # save history to tensorboard\n    # current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    train_log_dir = result_location +'/'+foldername +'/'+ train_num + '/train'\n    val_log_dir = result_location +'/'+foldername +'/'+ train_num + '/test'\n    train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n    val_summary_writer = tf.summary.create_file_writer(val_log_dir)\n\n    batch_num = math.ceil(noiseEEG.shape[0]/batch_size)\n    \n    datanum = noiseEEG.shape[1]\n    for epoch in range(epochs):\n        start = time.time()\n\n        # initialize  loss value for every epoch\n        mse_grads , train_mse = 0, 0\n\n        with tqdm(total=batch_num, position=0, leave=True) as pbar:\n    \n            for n_batch in range(batch_num):\n\n                #\n                if n_batch == batch_num:\n                    noiseEEG_batch,EEG_batch =  noiseEEG[batch_size*n_batch :] , EEG[batch_size*n_batch :]\n                else:\n                    noiseEEG_batch,EEG_batch =  noiseEEG[batch_size*n_batch : batch_size*(n_batch+1)] , EEG[batch_size*n_batch : batch_size*(n_batch+1)]\n\n                mse_loss_batch, mse_grads_batch = train_step(model, noiseEEG_batch,EEG_batch, optimizer, denoise_network, batch_size , datanum)\n\n                # convert variables to usable format\n                mse_grads_batch = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(mse_grads_batch)))).numpy()\n                mse_loss_batch = tf.reduce_mean(mse_loss_batch).numpy()\n\n                # store history \n                train_mse += mse_loss_batch/float(batch_num)\n                mse_grads += mse_grads_batch/float(batch_num)\n\n                pbar.update()\n            pbar.close()\n\n        # store train history \n        mse_grads_history.append(mse_grads)\n        train_mse_history.append(train_mse)\n\n        with train_summary_writer.as_default():\n            tf.summary.scalar('loss', train_mse, step=epoch)\n\n\n        # calculate mse loss for validation set\n        #denoiseoutput, val_mse, loss_rrmset = test_step(model, noiseEEG_val, EEG_val)\n        denoiseoutput, val_mse = test_step(model, noiseEEG_val, EEG_val)\n\n        #store validation history\n        val_mse_history.append(val_mse) \n\n        with val_summary_writer.as_default():   # record validation loss to tensorboard\n            tf.summary.scalar('loss', val_mse, step=epoch)\n\n        if epoch>epochs*0.2 and float(val_mse) < val_mse_min:  # if epoch_number > 0.8*all_epoch_number begin to save the best model  ## for SCNN or CCNN in EMG we should save the first or second model. \n            print('yes,smaller ', float(val_mse) ,val_mse_min)  \n            val_mse_min = float(val_mse)\n            saved_model = model\n            \n            # save dictionary to person_data.pkl file\n            with open('/kaggle/working/forpretrained/history.pkl', 'wb') as fp:\n                pickle.dump(history, fp)\n            #save model\n            model.save(\"/kaggle/working/forpretrained/my_model.keras\",saved_model)\n\n            path = os.path.join(result_location, foldername, train_num, \"denoise_model\")\n            tf.keras.models.save_model(model, path)\n            print('Best model has been saved')\n\n        print ('Epoch #: {}/{}, Time taken: {} secs,\\n Grads: mse= {},\\n Losses: train_mse= {}, val_mse={}'\\\n                     .format(epoch+1,epochs,time.time()-start , mse_grads,  train_mse, val_mse))\n\n            \n    #Generate after the final epoch\n    clear_output(wait=True)\n\n    #save history to dict\n    history['grads']['mse'] = mse_grads_history\n    history['loss']['train_mse'], history['loss']['val_mse']  = train_mse_history, val_mse_history\n        \n    return saved_model, history  ","metadata":{"execution":{"iopub.status.busy":"2024-05-05T23:19:54.037471Z","iopub.execute_input":"2024-05-05T23:19:54.037854Z","iopub.status.idle":"2024-05-05T23:19:54.069907Z","shell.execute_reply.started":"2024-05-05T23:19:54.037825Z","shell.execute_reply":"2024-05-05T23:19:54.068975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### save\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom functools import partial\nfrom tqdm import tqdm\nfrom IPython.display import clear_output \nimport os  \nimport math\n\n\ndef save_eeg(saved_model, result_location, foldername, save_train, save_vali, save_test, \n            noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, noiseEEG_test, EEG_test, train_num):\n\n    if save_train == True:\n        # generate every signal in training set\n        Denoiseoutput_train, train_mse = test_step(saved_model, noiseEEG_train, EEG_train)    \n\n        if not os.path.exists(result_location +'/'+  foldername + '/' +  train_num + '/' +\"nn_output\"):\n            os.makedirs(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\"   )\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" + '/' + \"noiseinput_train.npy\", noiseEEG_train)\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" + '/' +  \"Denoiseoutput_train.npy\", Denoiseoutput_train)               #######################   地址要改！！！！！！！！\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" + '/' +  \"EEG_train.npy\", EEG_train)\n\n    if save_vali == True:\n        # generate every signal in test set\n        Denoiseoutput_val, val_mse = test_step(saved_model, noiseEEG_val, EEG_val)        \n            \n        if not os.path.exists(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\"):\n            os.makedirs(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\")    \n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"noiseinput_val.npy\", noiseEEG_val)\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' +  \"Denoiseoutput_val.npy\", Denoiseoutput_val)                      #######################   地址要改！！！！！！！！\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"EEG_val.npy\", EEG_val)\n        \n    if save_test == True:\n        # generate every signal in test set\n\n        Denoiseoutput_test, test_mse = test_step(saved_model, noiseEEG_test, EEG_test)\n\n\n        if not os.path.exists(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\"):\n            os.makedirs(result_location +'/'+  foldername + '/' +  train_num + '/' + \"nn_output\")    \n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"noiseinput_test.npy\", noiseEEG_test)\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' +  \"Denoiseoutput_test.npy\", Denoiseoutput_test)                      #######################   地址要改！！！！！！！！\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"EEG_test.npy\", EEG_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T00:11:42.873914Z","iopub.execute_input":"2024-05-06T00:11:42.874671Z","iopub.status.idle":"2024-05-06T00:11:42.890144Z","shell.execute_reply.started":"2024-05-06T00:11:42.874638Z","shell.execute_reply":"2024-05-06T00:11:42.889133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### main\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom functools import partial\nfrom tqdm import tqdm\nfrom IPython.display import clear_output \nimport sys\nimport os\n#saving history\nimport pickle\n#sys.path.append('../')\nimport copy\n\n# EEGdenoiseNet V2\n# Author: Haoming Zhang \n# Here is the main part of the denoising neurl network, We can adjust all the parameter in the user-defined area.\n#####################################################自定义 user-defined ########################################################\n\nepochs =20 # training epoch\nbatch_size  = 40    # training batch size\ncombin_num = 10    # combin EEG and noise ? times\ndenoise_network = 'Complex_CNN'    # fcNN & Simple_CNN & Complex_CNN & RNN_lstm  & Novel_CNN \nnoise_type = 'EMG'\n\n\nresult_location = r'/kaggle/working/'     #  Where to export network results   ############ change it to your own location #########\nfoldername = 'EMG_unet112dense_10_rmsp_test'            # the name of the target folder (should be change when we want to train a new network)\nos.environ['CUDA_VISIBLE_DEVICES']='0'\nsave_train = False\nsave_vali = False\nsave_test = True\n\n\n################################################## optimizer adjust parameter  ####################################################\nrmsp=tf.optimizers.RMSprop(learning_rate=0.00005, rho=0.9)\nadam=tf.optimizers.Adam(learning_rate=0.00005, beta_1=0.5, beta_2=0.9, epsilon=1e-08)\n# sgd=tf.optimizers.legacy.SGD(learning_rate=0.0002, momentum=0.9, decay=0.0, nesterov=False)\n\noptimizer = rmsp\n\nif noise_type == 'EOG':\n  datanum = 1024  ##########changed\nelif noise_type == 'EMG':\n  datanum =1024\n\n\n# We have reserved an example of importing an existing network\n'''\npath = os.path.join(result_location, foldername, \"denoised_model\")\ndenoiseNN = tf.keras.models.load_model(path)\n'''\n#################################################### 数据输入 Import data #####################################################\n\nfile_location = '/kaggle/input/eeg-data/'                    ############ change it to your own location #########\nif noise_type == 'EOG':\n  EEG_all = np.load( file_location + 'EEG_all_epochs_512hz.npy')                              \n  noise_all = np.load( file_location + 'EOG_all_epochs.npy') \nelif noise_type == 'EMG':\n  EEG_all = np.load( file_location + 'EEG_all_epochs_512hz.npy')                              \n  noise_all = np.load( file_location + 'EMG_all_epochs_512hz.npy')\n\nimport scipy.io\nEOG_512Hz=scipy.io.loadmat(\"/kaggle/input/eog-all-epochs-512hz/eog_512Hz (1).mat\")\nEOG_data_512Hz=EOG_512Hz['eog_512Hz']\n\n############################################################# Running #############################################################\n#for i in range(10):\ni = 1     # We run each NN for 10 times to increase  the  statistical  power  of  our  results\n\nprev_history=False\nhistory={}\nif denoise_network == 'fcNN':\n    model = fcNN(datanum)\n\nelif denoise_network == 'Simple_CNN':\n  model = simple_CNN(datanum)\n\nelif denoise_network == 'Complex_CNN':\n  model = Complex_CNN(datanum)\n\nelif denoise_network == 'RNN_lstm':\n  model = RNN_lstm(datanum)\n\nelif denoise_network == 'Novel_CNN':\n  model = Novel_CNN(datanum)\n\n\nelse: \n    print('You are editing the same model')\n    model =tf.keras.saving.load_model(\"/kaggle/working/forpretrained/my_model.keras\")\n    #load\n    file_to_read = open(\"/kaggle/working/forpretrained/history.pkl\", \"rb\")\n    history = pickle.load(file_to_read)\n    print(history)\n    prev_history=True\n    noiseEEG_train=np.load(\"/kaggle/working/forpretrained/noiseEEG_train.npy\")\n    EEG_train=np.load(\"/kaggle/working/forpretrained/EEG_train.npy\")\n    noiseEEG_val=np.load(\"/kaggle/working/forpretrained/noiseEEG_val.npy\")\n    EEG_val=np.load(\"/kaggle/working/forpretrained/EEG_val.npy\")\n    noiseEEG_test=np.load(\"/kaggle/working/forpretrained/noiseEEG_test.npy\")\n    EEG_test=np.load(\"/kaggle/working/forpretrained/EEG_test.npy\")\nif prev_history==False:\n    noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, noiseEEG_test, EEG_test, test_std_VALUE = prepare_data(EEG_all = EEG_all, EMG_all = noise_all,EOG_all=EOG_data_512Hz, combin_num = 10, train_per = 0.8, noise_type = noise_type)\n    if not os.path.exists(\"/kaggle/working/forpretrained\"):\n                os.makedirs(\"/kaggle/working/forpretrained\")\n    np.save(\"/kaggle/working/forpretrained/noiseEEG_train.npy\",noiseEEG_train)\n    np.save(\"/kaggle/working/forpretrained/EEG_train.npy\",EEG_train)\n    np.save(\"/kaggle/working/forpretrained/noiseEEG_val.npy\",noiseEEG_val)\n    np.save(\"/kaggle/working/forpretrained/EEG_val.npy\",EEG_val)\n    np.save(\"/kaggle/working/forpretrained/noiseEEG_test.npy\",noiseEEG_test)\n    np.save(\"/kaggle/working/forpretrained/EEG_test.npy\",EEG_test)\n    ###may save test_std_VALUE\n\n\n\nsaved_model, history = train(model, noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, \n                      epochs, batch_size,optimizer, denoise_network, \n                      result_location, foldername , train_num = str(i),prev_history=prev_history,history=history)\n\n#denoised_test, test_mse = test_step(saved_model, noiseEEG_test, EEG_test)\n\n# save signal\nsave_eeg(saved_model, result_location, foldername, save_train, save_vali, save_test, \n                    noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, noiseEEG_test, EEG_test, \n                    train_num = str(i))\nnp.save(result_location +'/'+ foldername + '/'+ str(i)  +'/'+ \"nn_output\" + '/'+ 'loss_history.npy', history)\n\n#save model\n# path = os.path.join(result_location, foldername, str(i+1), \"denoise_model\")\n# tf.keras.models.save_model(saved_model, path)\n#save\nprint(history)\n# save dictionary to person_data.pkl file\nwith open('/kaggle/working/forpretrained/history.pkl', 'wb') as fp:\n    pickle.dump(history, fp)\n    print('dictionary saved successfully to file')\n    \n#save model , history, data:\nmodel.save(\"/kaggle/working/forpretrained/my_model.keras\",saved_model)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T23:20:05.069341Z","iopub.execute_input":"2024-05-05T23:20:05.069706Z","iopub.status.idle":"2024-05-05T23:48:52.753647Z","shell.execute_reply.started":"2024-05-05T23:20:05.069676Z","shell.execute_reply":"2024-05-05T23:48:52.752253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **for running optuna ***","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom functools import partial\nfrom tqdm import tqdm\nfrom IPython.display import clear_output \nimport os  \nimport math\nimport datetime\n\n# Author: Haoming Zhang\n# Here is the part of denoiseNet training process\n    \n\ndef test_step(model, noiseEEG_test, EEG_test):\n\n  denoiseoutput_test = model(noiseEEG_test)\n  loss = denoise_loss_mse(EEG_test, denoiseoutput_test)\n  #loss_rrmset = denoise_loss_rrmset(denoiseoutput_test, EEG_test)\n\n  return denoiseoutput_test, loss#, loss_rrmset\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom functools import partial\nfrom tqdm import tqdm\nfrom IPython.display import clear_output \nimport os  \nimport math\n\n\ndef save_eeg(saved_model, result_location, foldername, save_train, save_vali, save_test, \n            noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, noiseEEG_test, EEG_test, train_num):\n\n    if save_train == True:\n        # generate every signal in training set\n        Denoiseoutput_train, train_mse = test_step(saved_model, noiseEEG_train, EEG_train)    \n\n        if not os.path.exists(result_location +'/'+  foldername + '/' +  train_num + '/' +\"nn_output\"):\n            os.makedirs(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\"   )\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" + '/' + \"noiseinput_train.npy\", noiseEEG_train)\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" + '/' +  \"Denoiseoutput_train.npy\", Denoiseoutput_train)               #######################   地址要改！！！！！！！！\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" + '/' +  \"EEG_train.npy\", EEG_train)\n\n    if save_vali == True:\n        # generate every signal in test set\n        Denoiseoutput_val, val_mse = test_step(saved_model, noiseEEG_val, EEG_val)        \n            \n        if not os.path.exists(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\"):\n            os.makedirs(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\")    \n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"noiseinput_val.npy\", noiseEEG_val)\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' +  \"Denoiseoutput_val.npy\", Denoiseoutput_val)                      #######################   地址要改！！！！！！！！\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"EEG_val.npy\", EEG_val)\n        \n    if save_test == True:\n        # generate every signal in test set\n\n        Denoiseoutput_test, test_mse = test_step(saved_model, noiseEEG_test, EEG_test)\n\n\n        if not os.path.exists(result_location +'/'+  foldername + '/' +  train_num + '/'+ \"nn_output\"):\n            os.makedirs(result_location +'/'+  foldername + '/' +  train_num + '/' + \"nn_output\")    \n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"noiseinput_test.npy\", noiseEEG_test)\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' +  \"Denoiseoutput_test.npy\", Denoiseoutput_test)                      #######################   地址要改！！！！！！！！\n        np.save(result_location +'/'+  foldername + '/' + train_num + '/' + \"nn_output\" +'/' + \"EEG_test.npy\", EEG_test)\n        \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install optuna","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###for hyperparameter optimization\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom functools import partial\nfrom tqdm import tqdm\nfrom IPython.display import clear_output \nimport sys\nimport os\n#saving history\nimport pickle\n#sys.path.append('../')\nimport copy\n\nimport tensorflow as tf\nimport torch\nimport optuna\nimport logging\nimport sys\nimport gc\n\n#################################################### 数据输入 Import data #####################################################\n\nnoise_type = 'EMG'\nfile_location = '/kaggle/input/eeg-data/'     ########## change it to your own location #########\nif noise_type == 'EOG':\n    EEG_all = np.load( file_location + 'EEG_all_epochs_512hz.npy')                              \n    noise_all = np.load( file_location + 'EOG_all_epochs.npy') \nelif noise_type == 'EMG':\n    EEG_all = np.load( file_location + 'EEG_all_epochs_512hz.npy')                              \n    noise_all = np.load( file_location + 'EMG_all_epochs_512hz.npy')\n\nimport scipy.io \nEOG_512Hz=scipy.io.loadmat(\"/kaggle/input/eog-all-epochs-512hz/eog_512Hz (1).mat\")\nEOG_data_512Hz=EOG_512Hz['eog_512Hz']\n\nnoiseEEG_train, EEG_train, noiseEEG_val, EEG_val, noiseEEG_test, EEG_test, test_std_VALUE = prepare_data(EEG_all = EEG_all, EMG_all = noise_all,EOG_all=EOG_data_512Hz, combin_num = 1, train_per = 0.8, noise_type = 'EMG')\nif not os.path.exists(\"/kaggle/working/forpretrained\"):\n            os.makedirs(\"/kaggle/working/forpretrained\")\nnp.save(\"/kaggle/working/forpretrained/noiseEEG_train.npy\",noiseEEG_train)\nnp.save(\"/kaggle/working/forpretrained/EEG_train.npy\",EEG_train)\nnp.save(\"/kaggle/working/forpretrained/noiseEEG_val.npy\",noiseEEG_val)\nnp.save(\"/kaggle/working/forpretrained/EEG_val.npy\",EEG_val)\n\ndef objective(trial):\n    print('trial number: ',trial.number)\n    # Save the current trial number\n    trial_num_file = \"/kaggle/working/trial_num.pkl\"\n    with open(trial_num_file, \"wb\") as f:\n        pickle.dump(trial.number, f)\n        \n    epochs =3 # training epoch\n    batch_size  = 40    # training batch size\n    denoise_network = 'encoder_decoder'    # fcNN & Simple_CNN & Complex_CNN & RNN_lstm  & Novel_CNN \n    noise_type = 'EMG'\n\n\n    result_location = r'/kaggle/working/'     #  Where to export network results   ############ change it to your own location #########\n    foldername = 'EMG_unet112dense_10_rmsp_test'            # the name of the target folder (should be change when we want to train a new network)\n    os.environ['CUDA_VISIBLE_DEVICES']='0'\n    save_train = False\n    save_vali = False\n    save_test = True\n\n\n    if noise_type == 'EOG':\n        datanum = 1024  ##########changed\n    elif noise_type == 'EMG':\n        datanum =1024\n\n\n    # We have reserved an example of importing an existing network\n    '''\n    path = os.path.join(result_location, foldername, \"denoised_model\")\n    denoiseNN = tf.keras.models.load_model(path)\n    '''\n\n############################################################# Running #############################################################\n    i = 1     # We run each NN for 10 times to increase  the  statistical  power  of  our  results\n\n    prev_history=False\n    history={}\n    if denoise_network == 'fcNN':\n        model = fcNN(datanum)\n\n    elif denoise_network == 'Simple_CNN':\n      model = simple_CNN(datanum)\n\n    elif denoise_network == 'Complex_CNN':\n      model = Complex_CNN(datanum)\n\n    elif denoise_network == 'RNN_lstm':\n      model = RNN_lstm(datanum)\n\n    elif denoise_network == 'Novel_CNN':  \n      model = Novel_CNN(datanum)\n\n    elif denoise_network == 'Hybrid':  \n      model = Hybrid(datanum)\n    elif denoise_network == 'encoder_decoder':  \n      model = encoder_decoder(datanum)\n\n    noiseEEG_train=np.load(\"/kaggle/working/forpretrained/noiseEEG_train.npy\")\n    EEG_train=np.load(\"/kaggle/working/forpretrained/EEG_train.npy\")\n    noiseEEG_val=np.load(\"/kaggle/working/forpretrained/noiseEEG_val.npy\")\n    EEG_val=np.load(\"/kaggle/working/forpretrained/EEG_val.npy\")\n\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n\n    optimizer = tf.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n    \n\n    ######################train############################\n    @tf.function\n    def train_step(model, noiseEEG_batch, EEG_batch, optimizer , denoise_network, batch_size, datanum):\n\n        #本次训练参数初始化  parameter initialization in one step\n\n        mse_grads = 0\n        m_loss = 0\n\n\n        with tf.GradientTape() as loss_tape:\n\n            M_loss =  0\n            for x in range(noiseEEG_batch.shape[0]):\n\n                noiseeeg_batch,eeg_batch =  noiseEEG_batch[x] , EEG_batch[x]\n\n                if denoise_network == 'fcNN':\n                    noiseeeg_batch = tf.reshape(noiseeeg_batch, [1,datanum])\n                else:\n                    noiseeeg_batch = tf.reshape(noiseeeg_batch, [1,datanum,1])\n\n                eeg_batch=tf.reshape(eeg_batch, [1,datanum,1])\n                denoiseoutput = model(noiseeeg_batch)\n                denoiseoutput = tf.reshape(denoiseoutput, [1,datanum,1])                          \n\n                m_loss = denoise_loss_mse(denoiseoutput,eeg_batch)   \n                M_loss += m_loss\n\n\n            M_loss = M_loss / float(noiseEEG_batch.shape[0]) \n\n            # calculate gradient\n            mse_grads = loss_tape.gradient(M_loss, model.trainable_variables)\n            #bp\n            optimizer.apply_gradients(zip(mse_grads, model.trainable_variables))\n\n        return  M_loss,  mse_grads[0]  #每一条EEG的loss从此输出\n\n\n\n    def train(model, noiseEEG,EEG, noiseEEG_val, EEG_val, epochs, batch_size,optimizer, denoise_network, result_location, foldername, train_num,prev_history,history):\n        if prev_history ==False:\n            # setup history variables and save history in a npy film\n            history = {}\n            history['grads'], history['loss']= {}, {}\n            train_mse_history, val_mse_history = [],[]\n            mse_grads_history = []\n            val_mse_min = 100.0      # any number bigger than 1\n        else:\n            history=history\n            train_mse_history, val_mse_history = history['loss']['train_mse'], history['loss']['val_mse']\n            mse_grads_history = history['grads']['mse'] \n            hlv=history['loss']['val_mse']\n            val_mse_min = float(hlv[-1]) \n\n        print('We are in the train fn')    \n        # save history to tensorboard\n        # current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        train_log_dir = result_location +'/'+foldername +'/'+ train_num + '/train'\n        val_log_dir = result_location +'/'+foldername +'/'+ train_num + '/test'\n        train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n        val_summary_writer = tf.summary.create_file_writer(val_log_dir)\n\n        batch_num = math.ceil(noiseEEG.shape[0]/batch_size)\n\n        datanum = noiseEEG.shape[1]\n        for epoch in range(epochs):\n            start = time.time()\n\n            # initialize  loss value for every epoch\n            mse_grads , train_mse = 0, 0\n\n            with tqdm(total=batch_num, position=0, leave=True) as pbar:\n\n                for n_batch in range(batch_num):\n\n                    #\n                    if n_batch == batch_num:\n                        noiseEEG_batch,EEG_batch =  noiseEEG[batch_size*n_batch :] , EEG[batch_size*n_batch :]\n                    else:\n                        noiseEEG_batch,EEG_batch =  noiseEEG[batch_size*n_batch : batch_size*(n_batch+1)] , EEG[batch_size*n_batch : batch_size*(n_batch+1)]\n\n                    mse_loss_batch, mse_grads_batch = train_step(model, noiseEEG_batch,EEG_batch, optimizer, denoise_network, batch_size , datanum)\n\n                    # convert variables to usable format\n                    mse_grads_batch = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(mse_grads_batch)))).numpy()\n                    mse_loss_batch = tf.reduce_mean(mse_loss_batch).numpy()\n\n                    # store history \n                    train_mse += mse_loss_batch/float(batch_num)\n                    mse_grads += mse_grads_batch/float(batch_num)\n\n                    pbar.update()\n                pbar.close()\n\n            # store train history \n            mse_grads_history.append(mse_grads)\n            train_mse_history.append(train_mse)\n\n            with train_summary_writer.as_default():\n                tf.summary.scalar('loss', train_mse, step=epoch)\n\n\n            # calculate mse loss for validation set\n            #denoiseoutput, val_mse, loss_rrmset = test_step(model, noiseEEG_val, EEG_val)\n            denoiseoutput, val_mse = test_step(model, noiseEEG_val, EEG_val)\n\n            #store validation history\n            val_mse_history.append(val_mse) \n\n            with val_summary_writer.as_default():   # record validation loss to tensorboard\n                tf.summary.scalar('loss', val_mse, step=epoch)\n\n\n\n            if float(val_mse) < val_mse_min:  # if epoch_number > 0.8*all_epoch_number begin to save the best model  ## for SCNN or CCNN in EMG we should save the first or second model. \n                print('yes,smaller ', float(val_mse) ,val_mse_min)  \n                val_mse_min = float(val_mse)\n                saved_model = model\n\n                history['grads']['mse'] = mse_grads_history\n                history['loss']['train_mse'], history['loss']['val_mse']  = train_mse_history, val_mse_history\n                # save dictionary to person_data.pkl file\n                with open('/kaggle/working/forpretrained/history.pkl', 'wb') as fp:\n                    pickle.dump(history, fp)\n\n\n            print ('Epoch #: {}/{}, Time taken: {} secs,\\n Grads: mse= {},\\n Losses: train_mse= {}, val_mse={}'\\\n                         .format(epoch+1,epochs,time.time()-start , mse_grads,  train_mse, val_mse))\n\n\n        #Generate after the final epoch\n        clear_output(wait=True)\n\n        #save history to dict\n        history['grads']['mse'] = mse_grads_history\n        history['loss']['train_mse'], history['loss']['val_mse']  = train_mse_history, val_mse_history\n\n        return saved_model, history, val_mse\n\n\n    #############################\n    saved_model, history, val_mse_last = train(model, noiseEEG_train, EEG_train, noiseEEG_val, EEG_val, \n                      epochs, batch_size,optimizer, denoise_network, \n                      result_location, foldername , train_num = str(i),prev_history=prev_history,history=history)\n\n\n    print(history)\n    \n#     # Simulate a long training process...wait 1 sec\n#     time.sleep(1)\n\n    trial.report(val_mse_last,trial.number)\n    if trial.should_prune():\n        raise optuna.exceptions.PrialPruned\n    \n\n    return val_mse_last\n\n# Add stream handler of stdout to show the messages\noptuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\nstudy_name = \"mm-study\"  # Unique identifier of the study.\nstorage_name = \"sqlite:///{}.db\".format(study_name)\n\nstudy = optuna.create_study(direction='minimize',pruner=optuna.pruners.MedianPruner(),study_name=study_name, storage=storage_name, load_if_exists=True)\n\n# study = optuna.create_study(direction='minimize',pruner=optuna.pruners.MedianPruner(),study_name=study_name, storage=storage_name)\n\nstudy.optimize(objective, n_trials=50, callbacks=[lambda study, trial: gc.collect()])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import Sequential\nfrom tensorflow import keras\nimport shutil\nimport os\nimport optuna\nimport pickle\n\nshutil.copyfile(\"/kaggle/input/d/mayarmahmoud015/optuna/mm-study.db\", \"/kaggle/working/mm-study.db\")\n\n# Path to the trial number file\ntrial_num_file = \"/kaggle/input/d/mayarmahmoud015/optuna/trial_num.pkl\"\n\n# Load the trial number\nwith open(trial_num_file, \"rb\") as f:\n    trial_number = pickle.load(f)\n    print('trial_number: ',trial_number)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='minimize',pruner=optuna.pruners.MedianPruner(),study_name='mm-study', storage=\"sqlite:///{}.db\".format('mm-study'), load_if_exists=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from optuna.visualization import plot_contour\nfrom optuna.visualization import plot_edf\nfrom optuna.visualization import plot_intermediate_values\nfrom optuna.visualization import plot_optimization_history\nfrom optuna.visualization import plot_parallel_coordinate\nfrom optuna.visualization import plot_param_importances\nfrom optuna.visualization import plot_rank\nfrom optuna.visualization import plot_slice\nfrom optuna.visualization import plot_timeline\nplot_slice(study)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_optimization_history(study)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **end of optuna codes**","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# noiseEEG_test=np.load(\"/kaggle/working/forpretrained/noiseEEG_test.npy\")\n# EEG_test=np.load(\"/kaggle/working/forpretrained/EEG_test.npy\")\n# model =tf.keras.saving.load_model(\"/kaggle/working/forpretrained/my_model.keras\")\n# d = model(noiseEEG_test[5040].reshape(1,1024))\n# l1,=plt.plot(EEG_test[5040])\n# l2,=plt.plot(d[0])\n# plt.legend([l1,l2], ['Ground_truth','denoised 3layers 10ep'])\n# plt.show()\n\n# l3,=plt.plot(noiseEEG_test[5040])\n# plt.show()\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"denoise = model(noiseEEG_test)\nprint(denoise.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RRMSE\nRRMSE_total = 0\nRRMSE_arr = []\nfor j in range(10):\n    print(j)\n    for i in range(560):\n        RRMSE = denoise_loss_rrmset(denoise[560*j+i], EEG_test[560*j+i])\n        RRMSE_total = RRMSE_total + RRMSE\n    RRMSE_total = RRMSE_total/560\n    RRMSE_arr.append(RRMSE_total)\nprint(RRMSE_arr)\nimport numpy as np\nimport matplotlib.pyplot as plt\nsnr_values = np.linspace(-7, 2, 10)\nplt.plot(snr_values, RRMSE_arr, marker='o', linestyle='-')\nplt.xlabel('SNR (dB)')\nplt.ylabel('RRMSE')\nplt.title('LU-Net architecture')\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation\nimport numpy as np\ncorr_total = 0\ncorr_arr = []\nfor j in range(10):\n    print(j)\n    for i in range(560):\n        corr = np.corrcoef(denoise[560*j+i], EEG_test[560*j+i])[0,1]\n        corr_total = corr_total + corr\n    corr_total = corr_total/560\n    corr_arr.append(corr_total)\nprint(corr_arr)\nimport numpy as np\nimport matplotlib.pyplot as plt\nsnr_values = np.linspace(-7, 2, 10)\nplt.plot(snr_values, corr_arr, marker='o', linestyle='-')\nplt.xlabel('SNR (dB)')\nplt.ylabel('correlation')\nplt.title('LU-Net architecture')\nplt.grid(True)\nplt.show(","metadata":{},"execution_count":null,"outputs":[]}]}